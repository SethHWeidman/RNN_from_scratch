{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No layers, just:\n",
    "\n",
    "* Initialize LSTM Params\n",
    "* Write LSTM Model - sticking close to working example\n",
    "* Write LSTM Layer - sticking close to working example - use `t` to index time and use \"forward-backward\" functions.\n",
    "* Write LSTM node\n",
    "* Write \"sample\" fuction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def dsigmoid(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "\n",
    "def dtanh(y):\n",
    "    return 1 - y * y\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x)) #softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Param:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.deriv = np.zeros_like(value) #derivative\n",
    "        self.momentum = np.zeros_like(value) #momentum for AdaGrad\n",
    "        \n",
    "    def clear_gradient(self):\n",
    "        self.deriv = np.zeros_like(self.value) #derivative\n",
    "        \n",
    "    def clip_gradient(self):\n",
    "        self.deriv = np.clip(self.deriv, -1, 1, out=self.deriv)\n",
    "        \n",
    "    def update(self, learning_rate):\n",
    "        self.momentum += self.deriv * self.deriv # Calculate sum of gradients\n",
    "        self.value += -(learning_rate * self.deriv / np.sqrt(self.momentum + 1e-8))\n",
    "        \n",
    "    def update_sgd(self, learning_rate):\n",
    "        self.value -= learning_rate * self.deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Params:\n",
    "    \n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        self.stack_size = hidden_size + vocab_size\n",
    "        \n",
    "        self.W_f = LSTM_Param(np.random.normal(size=(self.stack_size, hidden_size), loc=0, scale=0.1))\n",
    "        self.W_i = LSTM_Param(np.random.normal(size=(self.stack_size, hidden_size), loc=0, scale=0.1))\n",
    "        self.W_c = LSTM_Param(np.random.normal(size=(self.stack_size, hidden_size), loc=0, scale=0.1))\n",
    "        self.W_o = LSTM_Param(np.random.normal(size=(self.stack_size, hidden_size), loc=0, scale=0.1))\n",
    "        self.W_v = LSTM_Param(np.random.normal(size=(hidden_size, vocab_size), loc=0, scale=0.1))\n",
    "        \n",
    "        self.B_f = LSTM_Param(np.zeros((1, hidden_size)))\n",
    "        self.B_i = LSTM_Param(np.zeros((1, hidden_size)))\n",
    "        self.B_c = LSTM_Param(np.zeros((1, hidden_size)))\n",
    "        self.B_o = LSTM_Param(np.zeros((1, hidden_size)))\n",
    "        self.B_v = LSTM_Param(np.zeros((1, vocab_size)))\n",
    "\n",
    "        \n",
    "    def all_params(self):\n",
    "        return [self.W_f, self.W_i, self.W_c, self.W_o, self.W_v, \n",
    "                self.B_f, self.B_i, self.B_c, self.B_o, self.B_v]\n",
    "        \n",
    "    def clear_gradients(self):\n",
    "        for param in self.all_params():\n",
    "            param.clear_gradient()\n",
    "        \n",
    "    def clip_gradients(self):\n",
    "        for param in self.all_params():\n",
    "            param.clip_gradient()       \n",
    "       \n",
    "    def update_params(self, learning_rate, method=\"ada\"):\n",
    "        for param in self.all_params():\n",
    "            if method == \"ada\":\n",
    "                param.update(learning_rate)  \n",
    "            elif method == \"sgd\":\n",
    "                param.update_sgd(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model:\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_size, learning_rate):\n",
    "        self.start_H = np.zeros((1, hidden_size))\n",
    "        self.start_C = np.zeros((1, hidden_size))\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.params = LSTM_Params(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward_backward(self, inputs, targets):\n",
    "\n",
    "        # To store the values for each time step\n",
    "        x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
    "        C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
    "        v_s, y_s =  {}, {}\n",
    "\n",
    "        # Values at t - 1\n",
    "        h_s[-1] = np.copy(self.start_H)\n",
    "        C_s[-1] = np.copy(self.start_C)\n",
    "\n",
    "        loss = 0\n",
    "        # Loop through time steps\n",
    "\n",
    "        for t in range(len(inputs)):\n",
    "            x_s[t] = np.zeros((1, self.vocab_size))\n",
    "            \n",
    "            x_s[t][0, inputs[t]] = 1 # Input character\n",
    "\n",
    "            (z_s[t], f_s[t], i_s[t],\n",
    "            C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
    "            v_s[t], y_s[t]) = \\\n",
    "                self.forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
    "\n",
    "            # The 0 included only because y_s is 2 dimensional (since we are using batch size 1)\n",
    "            loss += -np.log(y_s[t][0, targets[t]]) # Loss for at t\n",
    "\n",
    "        self.params.clear_gradients()\n",
    "\n",
    "        dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
    "        dC_next = np.zeros_like(C_s[0]) #dc from the next character\n",
    "\n",
    "        for t in reversed(range(len(inputs))):\n",
    "            # Backward pass\n",
    "            dh_next, dC_next = \\\n",
    "                self.backward(target = targets[t], dh_next = dh_next,\n",
    "                         dC_next = dC_next, C_prev = C_s[t-1],\n",
    "                         z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
    "                         C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
    "                         y = y_s[t])\n",
    "\n",
    "        self.params.clip_gradients()\n",
    "\n",
    "        self.start_H = h_s[len(inputs) - 1]\n",
    "        self.start_C = C_s[len(inputs) - 1]\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def forward(self, x, h_prev, C_prev):\n",
    "        assert x.shape == (1, self.vocab_size)\n",
    "        assert h_prev.shape == (1, self.hidden_size)\n",
    "        assert C_prev.shape == (1, self.hidden_size)\n",
    "\n",
    "        z = np.column_stack((h_prev, x))\n",
    "        \n",
    "        f = sigmoid(np.dot(z, self.params.W_f.value) + self.params.B_f.value)\n",
    "        i = sigmoid(np.dot(z, self.params.W_i.value) + self.params.B_i.value)\n",
    "        C_bar = tanh(np.dot(z, self.params.W_c.value) + self.params.B_c.value)\n",
    "\n",
    "        C = f * C_prev + i * C_bar\n",
    "        o = sigmoid(np.dot(z, self.params.W_o.value) + self.params.B_o.value)\n",
    "        h = o * tanh(C)\n",
    "\n",
    "        v = np.dot(h, self.params.W_v.value) + self.params.B_v.value\n",
    "        y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
    "\n",
    "        return z, f, i, C_bar, C, o, h, v, y\n",
    "\n",
    "\n",
    "    def backward(self, target, dh_next, dC_next, C_prev,\n",
    "                 z, f, i, C_bar, C, o, h, v, y):\n",
    "\n",
    "        assert z.shape == (1, self.vocab_size + self.hidden_size)\n",
    "        assert v.shape == (1, self.vocab_size)\n",
    "        assert y.shape == (1, self.vocab_size)\n",
    "\n",
    "        for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
    "            assert param.shape == (1, self.hidden_size)\n",
    "\n",
    "        dv = np.copy(y)\n",
    "        dv[0, target] -= 1\n",
    "\n",
    "        self.params.W_v.deriv += np.dot(h.T, dv)\n",
    "        self.params.B_v.deriv += dv\n",
    "\n",
    "        dh = np.dot(dv, self.params.W_v.value.T)        \n",
    "        dh += dh_next\n",
    "        do = dh * tanh(C)\n",
    "        do = dsigmoid(o) * do\n",
    "        self.params.W_o.deriv += np.dot(z.T, do)\n",
    "        self.params.B_o.deriv += do\n",
    "\n",
    "        dC = np.copy(dC_next)\n",
    "        dC += dh * o * dtanh(tanh(C))\n",
    "        dC_bar = dC * i\n",
    "        dC_bar = dtanh(C_bar) * dC_bar\n",
    "        self.params.W_c.deriv += np.dot(z.T, dC_bar)\n",
    "        self.params.B_c.deriv += dC_bar\n",
    "\n",
    "        di = dC * C_bar\n",
    "        di = dsigmoid(i) * di\n",
    "        self.params.W_i.deriv += np.dot(z.T, di)\n",
    "        self.params.B_i.deriv += di\n",
    "\n",
    "        df = dC * C_prev\n",
    "        df = dsigmoid(f) * df\n",
    "        self.params.W_f.deriv += np.dot(z.T, df)\n",
    "        self.params.B_f.deriv += df\n",
    "\n",
    "        dz = (np.dot(df, self.params.W_f.value.T)\n",
    "             + np.dot(di, self.params.W_i.value.T)\n",
    "             + np.dot(dC_bar, self.params.W_c.value.T)\n",
    "             + np.dot(do, self.params.W_o.value.T))\n",
    "        dh_prev = dz[:, :self.hidden_size]\n",
    "        dC_prev = f * dC\n",
    "\n",
    "        return dh_prev, dC_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Character_generator:\n",
    "    def __init__(self, text_file, LSTM_Model, sequence_length):\n",
    "        self.data = open(text_file, 'r').read()\n",
    "        self.model = LSTM_Model\n",
    "        self.chars = list(set(self.data))\n",
    "        self.vocab_size = len(self.chars)\n",
    "        self.char_to_idx = {ch:i for i,ch in enumerate(self.chars)}\n",
    "        self.idx_to_char = {i:ch for i,ch in enumerate(self.chars)}\n",
    "        self.iterations = 0\n",
    "        self.start_pos = 0\n",
    "        self.sequence_length = sequence_length\n",
    "        self.smooth_loss = -np.log(1.0 / self.vocab_size) * self.sequence_length\n",
    "    \n",
    "    def _generate_inputs_targets(self, start_pos):\n",
    "        inputs = ([self.char_to_idx[ch] \n",
    "                   for ch in self.data[start_pos: start_pos + self.sequence_length]])\n",
    "        targets = ([self.char_to_idx[ch] \n",
    "                    for ch in self.data[start_pos + 1: start_pos + self.sequence_length + 1]])\n",
    "        return inputs, targets\n",
    "\n",
    "\n",
    "    def sample_output(self, input_char, sample_length):\n",
    "        \n",
    "        x = np.zeros((1, self.vocab_size))\n",
    "        x[0, input_char] = 1\n",
    "        \n",
    "        \n",
    "        sample_model = deepcopy(self.model)\n",
    "        \n",
    "        indices = []\n",
    "        for char in range(sample_length): \n",
    "            _, _, _, _, _, _, _, _, p = sample_model.forward(x, \n",
    "                                                             sample_model.start_H, \n",
    "                                                             sample_model.start_C)\n",
    "            idx = np.random.choice(range(self.vocab_size), p=p.ravel())\n",
    "            \n",
    "            x = np.zeros((1, self.vocab_size))\n",
    "            x[0, idx] = 1.0\n",
    "            indices.append(idx)\n",
    "            \n",
    "        txt = ''.join(self.idx_to_char[idx] for idx in indices)\n",
    "        return txt\n",
    "    \n",
    "    \n",
    "    def single_step(self):\n",
    "   \n",
    "        inputs, targets = self._generate_inputs_targets(self.start_pos)\n",
    "        \n",
    "        loss = self.model.forward_backward(inputs, targets)\n",
    "            \n",
    "        self.model.params.update_params(self.model.learning_rate)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def training_loop(self, num_iterations, ):\n",
    "        \n",
    "        plot_iter = np.zeros((0))\n",
    "        plot_loss = np.zeros((0))\n",
    "        \n",
    "        num_iter = 0\n",
    "        \n",
    "        while num_iter < num_iterations:\n",
    "            \n",
    "            if self.start_pos + self.sequence_length > len(self.data):\n",
    "                self.start_pos = 0\n",
    "            \n",
    "            loss = self.single_step()\n",
    "            \n",
    "            self.start_pos += self.sequence_length\n",
    "                \n",
    "            plot_iter = np.append(plot_iter, [num_iter])\n",
    "            plot_loss = np.append(plot_loss, [loss])\n",
    "            \n",
    "            if num_iter % 100 == 0:\n",
    "                plt.plot(plot_iter, plot_loss)\n",
    "                display.clear_output(wait=True)\n",
    "                plt.show()\n",
    "                \n",
    "                sample_text = self.sample_output(self.char_to_idx[self.data[self.start_pos]], \n",
    "                                                 200)\n",
    "                print(sample_text)\n",
    "\n",
    "            self.start_pos += self.sequence_length\n",
    "            num_iter += 1\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115bb6b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revisoushinounoplealenoupofo whisanahigranoupofapa myobevinoublisowelanogerithevinouprelowhebrePalifowitupecovube upeveanofrithononofe ma wexinous a myoupareveflofeprevevenofineexchitha alenoblinwhamy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-121e848a12ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m62\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcharacter_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCharacter_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcharacter_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-4df8adcf3c8e>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(self, num_iterations)\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-4df8adcf3c8e>\u001b[0m in \u001b[0;36msingle_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_inputs_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-595023e96544>\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mC_bar_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             v_s[t], y_s[t]) = \\\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# The 0 included only because y_s is 2 dimensional (since we are using batch size 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-152-595023e96544>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_prev, C_prev)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mC_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC_prev\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mC_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mod = LSTM_Model(vocab_size=62, hidden_size=100, learning_rate=0.1)\n",
    "character_generator = Character_generator('input.txt', mod, sequence_length=25)\n",
    "character_generator.training_loop(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement LSTM_Step using forward_backward from other code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
